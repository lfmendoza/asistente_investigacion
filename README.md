# üîç Asistente de Investigaci√≥n Digital

Esta aplicaci√≥n web interactiva funciona como un asistente de investigaci√≥n digital, capaz de buscar informaci√≥n actualizada en la web, analizarla utilizando modelos de lenguaje y presentar un resumen junto con una visualizaci√≥n interactiva de las palabras m√°s frecuentes.

## üìã Caracter√≠sticas

- B√∫squeda web con la API de Tavily a trav√©s de un agente ReAct de LangChain
- Presentaci√≥n amigable de resultados (t√≠tulo, contenido, enlaces)
- Generaci√≥n autom√°tica de res√∫menes con OpenAI (GPT-4-mini)
- Visualizaci√≥n interactiva con nubes de palabras
- Interfaz de usuario intuitiva desarrollada con Streamlit

## üöÄ Instalaci√≥n

### Requisitos previos

- Python 3.9 o superior
- Claves API para OpenAI y Tavily

### Pasos de instalaci√≥n

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/lfmendoza/asistente_investigacion.git
   cd asistente_investigacion
   ```

2. Crear y activar un entorno virtual (opcional pero recomendado):
   ```bash
   python -m venv venv
   
   # En Windows
   venv\Scripts\activate
   
   # En macOS/Linux
   source venv/bin/activate
   ```

3. Instalar las dependencias:
   ```bash
   pip install -r requirements.txt
   ```

4. Configurar las claves API:
   ```bash
   cp .env.example .env
   ```
   
   Edita el archivo `.env` y agrega tus claves API:
   ```
   OPENAI_API_KEY=tu_clave_de_openai
   TAVILY_API_KEY=tu_clave_de_tavily
   ```

## üíª Uso

1. Iniciar la aplicaci√≥n:
   ```bash
   streamlit run app.py
   ```

2. Abrir el navegador en la direcci√≥n mostrada (generalmente http://localhost:8501)

3. Ingresar un tema de inter√©s en el campo de texto y hacer clic en "Buscar informaci√≥n"

4. Explorar los resultados, el resumen y las visualizaciones generadas

## üèóÔ∏è Estructura del proyecto

```
asistente_investigacion/
‚îú‚îÄ‚îÄ .env.example                # Plantilla para las claves de API
‚îú‚îÄ‚îÄ README.md                   # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ app.py                      # Punto de entrada principal de Streamlit
‚îî‚îÄ‚îÄ modulos/
    ‚îú‚îÄ‚îÄ __init__.py             # Hace que el directorio sea un paquete
    ‚îú‚îÄ‚îÄ buscador.py             # M√≥dulo para la b√∫squeda con Tavily
    ‚îú‚îÄ‚îÄ procesador.py           # M√≥dulo para procesamiento con OpenAI
    ‚îî‚îÄ‚îÄ visualizador.py         # M√≥dulo para visualizaci√≥n (WordCloud)
```

## üìö Descripci√≥n de los m√≥dulos

### `modulos/buscador.py`

Este m√≥dulo se encarga de realizar b√∫squedas web utilizando la API de Tavily a trav√©s de LangChain. Implementa un agente ReAct que busca informaci√≥n relevante sobre el tema proporcionado por el usuario.

Funciones principales:
- `inicializar_agente_busqueda()`: Configura el agente ReAct con la herramienta de b√∫squeda.
- `realizar_busqueda(tema)`: Ejecuta la b√∫squeda y procesa los resultados.
- `obtener_texto_completo(resultados)`: Extrae todo el texto de los resultados para an√°lisis posterior.

### `modulos/procesador.py`

Este m√≥dulo utiliza la API de OpenAI para analizar y procesar el texto obtenido de las b√∫squedas.

Funciones principales:
- `generar_resumen(texto, tema)`: Genera un resumen del contenido utilizando GPT-4-mini.
- `preprocesar_texto_para_wordcloud(texto)`: Preprocesa el texto para generar una nube de palabras m√°s relevante.

### `modulos/visualizador.py`

Este m√≥dulo se encarga de generar visualizaciones a partir del texto procesado.

Funciones principales:
- `generar_nube_palabras(texto)`: Genera una nube de palabras a partir del texto.
- `contar_palabras_frecuentes(texto, n)`: Cuenta las palabras m√°s frecuentes en el texto.

## üõ†Ô∏è Tecnolog√≠as utilizadas

- **Streamlit**: Para la interfaz de usuario web
- **LangChain**: Para la integraci√≥n de modelos de lenguaje y herramientas
- **OpenAI API**: Para el procesamiento de lenguaje natural
- **Tavily API**: Para la b√∫squeda de informaci√≥n en la web
- **WordCloud y Matplotlib**: Para la visualizaci√≥n de datos
- **Python-dotenv**: Para la gesti√≥n de variables de entorno

## üì¶ Requisitos

```
streamlit==1.32.0
requests==2.31.0
openai==1.12.0
python-dotenv==1.0.0
langchain==0.1.4
langchain-openai==0.0.5
matplotlib==3.8.2
wordcloud==1.9.2
```

## ü§î Reflexi√≥n cr√≠tica sobre el uso de IA para buscar y procesar informaci√≥n

El uso de inteligencia artificial para buscar y procesar informaci√≥n representa un avance significativo en la manera en que accedemos al conocimiento, pero tambi√©n plantea importantes consideraciones:

### Ventajas
- **Eficiencia**: La IA puede analizar grandes vol√∫menes de informaci√≥n en segundos, algo imposible para un humano.
- **Acceso a informaci√≥n diversa**: Permite obtener una visi√≥n m√°s amplia y variada sobre un tema espec√≠fico.
- **Reducci√≥n de sesgos humanos**: Potencialmente puede reducir algunos sesgos cognitivos presentes en la investigaci√≥n humana.
- **Personalizaci√≥n**: Adapta los resultados a necesidades espec√≠ficas del usuario.

### Desaf√≠os y limitaciones
- **Calidad y veracidad**: La IA no siempre distingue informaci√≥n veraz de la falsa, pudiendo propagar desinformaci√≥n.
- **Sesgos algor√≠tmicos**: Los sistemas pueden reflejar y amplificar sesgos presentes en sus datos de entrenamiento.
- **Falta de pensamiento cr√≠tico**: La IA carece de la capacidad humana para evaluar cr√≠ticamente el contexto y la fiabilidad de las fuentes.
- **Dependencia tecnol√≥gica**: Puede reducir las habilidades de investigaci√≥n independiente de los usuarios.
- **Burbujas informativas**: Los algoritmos pueden reforzar creencias existentes al mostrar informaci√≥n que coincide con preferencias previas.

### Consideraciones √©ticas
- Es crucial mantener la transparencia sobre cu√°ndo la informaci√≥n ha sido procesada por IA.
- Los usuarios deben desarrollar alfabetizaci√≥n digital para evaluar cr√≠ticamente los resultados.
- El papel humano en la verificaci√≥n y contextualizaci√≥n de la informaci√≥n sigue siendo insustituible.

Esta aplicaci√≥n busca ser una herramienta complementaria que potencie las capacidades de investigaci√≥n humanas, no reemplazarlas. El objetivo es proporcionar un punto de partida eficiente para explorar temas, pero siempre fomentando el an√°lisis cr√≠tico y la verificaci√≥n de fuentes por parte del usuario.

## üìÑ Licencia

Este proyecto est√° bajo la Licencia MIT - ver el archivo LICENSE para m√°s detalles.

## üôè Agradecimientos

- Equipo de OpenAI por proporcionar la API para el procesamiento de lenguaje natural
- Equipo de Tavily por su API de b√∫squeda web
- Comunidad de Streamlit por crear una herramienta tan vers√°til para aplicaciones web en Python
- Desarrolladores de LangChain por facilitar la integraci√≥n de modelos de lenguaje con herramientas